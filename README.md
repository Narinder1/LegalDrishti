# LegalDrishti

AI-powered Legal Assistant platform for India. Built with Next.js, FastAPI, and Ollama.

## ğŸš€ Features

- ğŸ¤– **AI Legal Assistant** - Chat with Gemma AI for legal guidance
- ğŸ“„ **Document Processing** - OCR & document analysis (coming soon)
- ğŸ” **Legal Search** - Search case laws & acts (coming soon)
- ğŸ“ **Templates** - Legal document templates (coming soon)

## ğŸ“ Project Structure

```
LegalDrishti/
â”œâ”€â”€ .env                 # Environment variables (shared)
â”œâ”€â”€ .env.example         # Environment template
â”œâ”€â”€ .gitignore           # Git ignore rules
â”œâ”€â”€ README.md            # This file
â”œâ”€â”€ backend/             # FastAPI backend
â”‚   â”œâ”€â”€ run.py           # Start server
â”‚   â”œâ”€â”€ requirements.txt # Python dependencies
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py      # FastAPI app
â”‚       â”œâ”€â”€ api/v1/      # API routes
â”‚       â”œâ”€â”€ core/        # Config & dependencies
â”‚       â”œâ”€â”€ schemas/     # Pydantic models
â”‚       â”œâ”€â”€ services/    # Business logic
â”‚       â””â”€â”€ utils/       # Helper functions
â””â”€â”€ frontend/            # Next.js frontend
    â”œâ”€â”€ package.json
    â””â”€â”€ src/
        â”œâ”€â”€ app/         # Pages
        â””â”€â”€ components/  # React components
```

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|------------|
| Frontend | Next.js 14, React 18, TypeScript, Tailwind CSS |
| Backend | FastAPI, Python 3.10+, Pydantic |
| AI/LLM | Ollama, Gemma 3 1B |
| Database | PostgreSQL (coming soon) |

## âš¡ Quick Start

### Prerequisites

- Python 3.10+
- Node.js 18+
- [Ollama](https://ollama.ai/) installed

### 1. Clone & Setup

```bash
git clone <your-repo-url>
cd LegalDrishti

# Copy environment file
cp .env.example .env
```

### 2. Start Ollama

```bash
# Start Ollama service
ollama serve

# Pull the model (first time only)
ollama pull gemma3:1b
```

### 3. Start Backend

```bash
cd backend

# Install dependencies (first time only)
pip install -r requirements.txt

# Start server
python run.py
```

Backend runs at: http://localhost:8000
API Docs: http://localhost:8000/docs

### 4. Start Frontend

```bash
cd frontend

# Install dependencies (first time only)
npm install

# Start dev server
npm run dev
```

Frontend runs at: http://localhost:3000

## ğŸ“‹ Commands Reference

| Action | Command |
|--------|---------|
| Start Backend | `cd backend && python run.py` |
| Start Frontend | `cd frontend && npm run dev` |
| Start Ollama | `ollama serve` |
| Pull Model | `ollama pull gemma3:1b` |
| Install Backend Deps | `cd backend && pip install -r requirements.txt` |
| Install Frontend Deps | `cd frontend && npm install` |

## ğŸ”§ Environment Variables

All environment variables are in the root `.env` file:

```env
# Application
APP_NAME=LegalDrishti
DEBUG=True

# Ollama LLM
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:1b

# Frontend
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/chat/chat` | Send message to AI |
| POST | `/api/chat/quick-action` | Predefined prompts |
| GET | `/api/chat/model-info` | Get model information |
| GET | `/health` | Health check |
| GET | `/docs` | Swagger API docs |

## ğŸ§ª Testing the API

```bash
# Health check
curl http://localhost:8000/health

# Chat with AI
curl -X POST http://localhost:8000/api/chat/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What is a contract?"}'
```

## ğŸš€ Production Deployment

### Backend
```bash
# Without reload for production
cd backend
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### Frontend
```bash
cd frontend
npm run build
npm start
```

### Ollama in Production
- Self-host on GPU server (Vast.ai, RunPod)
- Or use Groq API (free tier available)

## ğŸ“ License

MIT License

## ğŸ‘¥ Team

Built by the LegalDrishti Team
